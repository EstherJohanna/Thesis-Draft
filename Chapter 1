\chapter{Introduction} 

\label{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Take Over!}

While holding a cup of coffee and her cell phone in the one hand, Alice is trying to put back on her son's sock with the other. Struggling with his stubborn resistance, she is looking for a place to put down the cup of coffee, when suddenly a loud sound brings her back to reality: `Please take over driving!', a friendly voice requests. While Alice is hectically trying to find a place for her coffee cup, the noise becomes louder and more urgent. Her son starts crying, and when Alice looks out of the windshield she sees that her car is rapidly approaching road works blocking the street in front of her...
\\
Is Alice ready to take over driving now? And if no, how long does it take until she is?
\\
This scenario could be a realistic situation within a few year's time. Bosch and Daimler promised to get highly automated driving cars on the road by 2020 (\cite{}). Compared to completely autonomous cars, highly automated cars (SAE and BASt Level 3, see Fig. \ref{64}) have one relevant difference: there will be situations coming up that require a human driver to take over the driving task. Highly automated driving on SAE Level three will allow the driver to completely disengage from the driving task for certain periods of times. During these, the driver will be allowed to occupy with any task he likes to. These tasks are only limited by that the driver has to be able to perceive the takeover request. Most likely, he will also have to stay seated in the driver seat. These activities can range from doing nothing to the above-mentioned example - and everything in between. At any moment, there are options for a takeover to become necessary. One is that the car's sensors fail, another that unexpected situations (like a road block) occur, amongst others. For these cases, the human driver is needed as a fall-back option. Depending on his current state, the driver will take longer or shorter until he is ready to take over manual driving. For every driver state, it needs to be clear how long he would need to be ready. In case that a critical scenario will be reached before the driver is ready, the car enters a minimal-risk state like parking on the hard shoulder. On the other hand, it is not desirable to have a long row of parked cars in front of any road block. Therefore, if the driver is estimated to be ready to take over in time, he should be requested to take over. For this, it is essential to estimate driver readiness appropriately. 

\begin{figure}
\centering
\includegraphics[width = 1\textwidth]{Figures/64}
\decoRule
\caption{SAE and BASt levels of automation. From cyberlaw.stanford.edu/loda.}
\label{64}
\end{figure}


Why worry about highly automated driving when completely autonomous cars are already on the way, one might wonder? Tesla and Google are driving on US roads completely automated - only for trials, until now. But Tesla's CEO Elon Musk announces first fully autonomous cars to be publicly available by 2019 \cite{}. What makes highly automated driving relevant are user acceptance and law adaptation. Cars will drive automated only on highways in the coming years. Law changes for that case are much easier than for fully autonomous cars. Algorithms for highways do not have to take into account the danger of surrounding pedestrians, bikes, crossroads etc. This means there will always be a moment in which the highway exit approaches - and the human driver needs to take back control.  Blabla even says that fully autonomous cars will be accepted or allowed in Europe \cite{FAZ Artikel}.  

What in the end decides whether highly automated driving will sell or not is user acceptance. Therefore, it is essential to keep the human in mind when designing solutions on HAD. The transition from automated to manual driving should not only be safe, but also comfortable. For this, several factors have to be taken into account. For example, a takeover will take longer when the driver is tired, extremely distracted by a secondary task, or positioned in a way that will make it time-intensive to turn back to the steering wheel. The car needs to notice this difference and take it into account by warning the driver earlier. That way, the driver will be requested to take over at a time that, depending on driver state and given situation, warns early enough to make a comfortable and safe takeover possible. 
%----------------------------------------------------------------------------------------

\section{Related Work}
\subsection{Taking Over Control in Highly Automated Driving}

literature table machen
plot of takeover times of different studies

The Society of Automotive Engineers (SEA) formulated as one of the requirements for SAE Level 3 that it is expected that `the human driver will respond appropriately to a request to intervene'. Since that, numerous studies have tried to determine experimentally how much time the driver needs in order to ensure this `appropriate response'. The two most important measures during those studies are takeover time and takeover quality. This thesis will focus on takeover time, which is usually defined as the time from a request to intervene (=takeover request) to either braking, steering or a button press.

%The definition of takeover time varies between publications. While for most the takeover time is the time from the takeover request to the first steering, braking, acceleration or a button press, for others it is bla. Also, it differs whether the drivers were able to   accidentally   see the obstacle before the takeover request, or whether it appeared together with the request. In this thesis, takeover time will refer only to the time from takeover request to braking steering, acceleration or button press when the obstacle was not visible before. Everything else will be explicitly mentioned. Takeover quality has been measured in several ways, some of them being bla , bla and bla. 

The time budget is the time from takeover request to an obstacle or the end of scenario. All of the following studies were conducted in a driving simulator. An overview can be found in Table \ref{litOverview}. In 2012, Damböck et al. started off with giving the driver a time budget of 4, 6 or 8 seconds and evaluating how many mistakes (lane deviation, crash into obstacle, ...) the driver made (\cite{uebernahmeHAF}). He found that while most people would have crashed into the obstacle at a four second time budget, they made it with 6 seconds while making many mistakes, and mostly were fine with an 8 second time budget. Gold et al. then conducted a study measuring takeover time and quality, depending on the time budget of 5 or 7 seconds (\cite{Gold2013}). He found that from take-over request to braking it takes on average 2.06 second in the 5 second time budget condition, and 3.1 seconds in the 7 second time budget condition. Thus, we assume that with a shorter time budget, the driver's perception of urgency decreases his reaction time. On the other hand, Gold found that takeover quality decreases with a shorter time budget. Petermann-Stock et al. find takeover times with a mean of 2.3 seconds and a maximum of 8 seconds depending on age and non-driving related tasks (\cite{petermann2013lange}). Naujoks et al. showed that participants react faster to visual-auditory than only visual take-over request, with average take-over times of 6.9 and 2.3 seconds, respectively (\cite{naujoks2014effect}). Radlmayr et al. test different traffic densities and non-driving related tasks. They find times from takeover request to steering or braking of 1.55 to 2.92 seconds on average, with a maximum of 4.55 seconds. They find a significant difference for traffic density, but not NDTR. Gold et al. one year later does find a significant influence of non-driving related tasks, with a takeover time of 1.3 seconds without a task, and 2.2 seconds in the most demanding (`motor-cognitive') task (\cite{Gold2015}). Another study investigating the influence of non-driving elated tasks was Befelein et al, who tested four non-driving related tasks and found takeover times between 2.4 to 4.8 seconds (\cite{befelein2016}). By far the longest takeover times were found by Eriksson et al., who investigated noncritical takeover situations and non-driving related tasks (\cite{eriksson2016take}). He found takeover times between 2 to 25.6 seconds. Also Vollrath et al. investigate secondary tasks, finding that for drivers who played tetris it took 11.2 seconds until all drivers had taken over; for reading drivers it took 9 seconds and observing drivers 7 seconds before everyone had taken over (\cite{unfallforschung}). 
Lorenz et al. show a mean takeover time of 2.91 with augmented reality support (\cite{Lorenz2014}). This time only very slightly differs between a positive   (where to go) , a negative (where not to go) assisting augmented reality and the control condition without support. Strand et al. test how long subjects need to take over in case of automation failure and finds mean takeover times from 1.85 to 2.57 seconds in the highly automated condition. These times are not fully comparable because no request to intervene was issued and conditions differed in the level of failure between moderate, severe or complete (\cite{strand2014semi}). Whether the modality and presentation of the TOR make a difference was tested in Melcher 2015, who found takeover times of 3.42 to 3.77 seconds but no significant difference between the tested conditions (\cite{melcher2015take}). Also Belderbos et al. checking for the influence of different human machine interfaces with a mean takeover time of 5.9 seconds did not find an influence of his conditions (\cite{belderbos2015authority}). Contrary to that, Kerschbaum et al. do find an influence of a transformable steering wheel with mean takeover times from 2.22 to 3.09 seconds (\cite{kerschbaum2015transforming}). Walch et al. investigate time budgets of four and six seconds, with and without alert about fog coming up. They find takeover times from 1.8 seconds with 6 seconds time budget and an obstacle blocking the road, to 2,75 seconds when there is no road block and the driver is even alerted before the takeover request (\cite{walch2015autonomous}). Interestingly, people here take significantly longer for the takeover if an alert has been issued before the takeover request. They are faster at taking over if there is a road block that needs to be avoided. Zeeb et al. classify drivers into high-, medium- and low risk gaze behavior types which take 2.31, 1.86 and 1.63 seconds for taking over, respectively (\cite{Zeeb2015}). She concludes that gaze behavior predicts cognitive, but not motor readiness. Körber et al. find that a subject's previously measured multitasking ability predicts their takeover time (\cite{Koerber2015}). Here, it should be considered that he showed the obstacle before the takeover request, which lead to times of 600ms, 20ms, -800ms, -500ms and -1800ms. The negative number indicates that the subject took over before the takeover request. Louw et al. conduct their experiments on a computer screen (\cite{louw2015engaging}). They find takeover times from 1.7 to 2.5 seconds, and tested manual against automated driving and automated distracted driving. Additionally, drivers had to evade to the left or right depending on the color of the broken down vehicle. Payre et al. tested for the influence of trust and practice finding takeover times of 2 to 15 seconds (\cite{payre2016fully}). It should be mentioned that they did not warn participants that a takeover request would occur. Feldhuetter et al. found means of 1.88 to 2.24 seconds when making a takeover request after either 5 or 20 minutes of driving (\cite{feldhutter2016duration}). This was no significant difference. Körber et al. found no influence of age on takeover time, which had means of 2.4 to 3.6 seconds (\cite{korber2016influence}). Another study by Gold found a relevant influence of traffic density, but not the secondary task of 20 questions (means from 2.5 to 3.6) (\cite{gold2016taking}). Maas found an influence of information presentation (camera vs. abstract cue) and means from 1.9 to 3 seconds (\cite{maas2016losungsansatze}). Zeeb finds no influence of nondriving related tasks and means from 2.4 to 3.5 seconds in her next study (\cite{zeeb2016take}). In his 2016 study, Bueno finds means of around 3.6 seconds in both of his conditions for mental workload (\cite{bueno2016different}). 
\\
Of course, it can be questioned how well these studies reflect actual takeover times in `real life'. One problem is that they were all conducted in simulators, which only limitedly imitates real road conditions, and especially the urgency of the situation is different than on a real road. People might react completely different when confronted with the same situation in real life. Another problem are the short times between takeover requests: Studies request to take over every minute to five minutes. Much longer takeover times would be impossible to measure in a realistic experimental setup. On the contrary, drivers will have breaks of hours, days or even months between takeover requests when used in real cars. Regular trainings, similar to how it is already done in aviation, should ensure that drivers still safely know how to drive when manually driving.  

Still, these studies give a good estimate of how much time the human should be given in case he needs to take back control. Therefore, we will discuss different models for predicting takeover time in the following (?). 

\begin{table}
 \centering
  \begin{tabular}{ c | c | c | c | c | c }
    \hline
    
     & Data & Model \\ \hline
     Befelein - Baseline & 2.4 & 3.55 \\ \hline
     Befelein - calculate &3.8 & 3.7\\ \hline
     Befelein - search & 3.5 & 5.72\\ \hline
     Befelein - watch Video&4&5.7\\ \hline
     Befelein - Tetris& 4.7&5.7 \\ \hline
     Gold - Baseline &2.49&2.77\\ \hline
     Gold - Traffic&3.46 & 4.36\\ \hline
     Gold - Mental Workload & 2.69 & 2.92  \\ \hline
     Gold - Mental Workload and Traffic & 3.61 & 4.51\\ \hline
    
  \end{tabular}
 \caption{Overview of literature about takeover time.}
\end{table}\label{litOverview}


\subsection{Driver Modeling}

everything I have in gold bla the modeling jabref. not using machine learning etc because I dont have data. and because I dont want a black box. then salvucci and why that  s the only true way. mention mioch.


%----------------------------------------------------------------------------------------

\section{Theoretical Background}

\subsection{Regression Analysis}

Regression analysis tries to predict a dependent variable from one or multiple independent variable(s). It can be and is used in pretty much any field: rent indices (rent predicted by square meters, location,...), ................ (\cite{fahrmeir2007regression}). In a linear regression, one tries to fit the data of the dependent variable by a line (see Fig. \ref{}). The line's intercept and slope are determined by an equation that looks like equation \ref{reg}. It is also possible to fit by a logarithmic or any other function. Regression analysis is also the basis of machine learning, which lately became a popular tool used for pretty much anything.

\begin{equation}
\begin{split}
TakeOverTime = \beta_{0} + \beta_{1} \cdot IndependentVariable_1 + \beta_{2} \cdot IndependentVariable_2 + \\
\beta_{3} \cdot IndependentVariable_3 + .... \beta_{i} \cdot IndependentVariable_i  + \epsilon_{i}
 \end{split}
\end{equation} \label{reg}

\subsection{Cognitive Architectures}

Cognitive Architectures are Artificial Intelligence that does not try to be perfect, but exactly like a human. They can model human behavior on different levels: While some model on the low level at the basis of neuronal firing (Nengo, cite bla), others model on task (ACT-R cite bla) or even multiple task level (PRIMs cite bla). Because we were interested in high-level behavior modeling, the subsequent introduction will outline the basics of ACT-R. 

Of cognitive architectures, ACT-R is the best known (and therefore best described) one. Other cognitive architectures exist, but most of them are not publicly available. The following explanations are based on the slides about ACT-R and PRIMS (which work very similar) from the Spring School on Cognitive Architectures in Groningen, 2017.
\\
ACT-R consists of five modules that represent these cortical areas that are most relevant for modeling certain human behaviors. Those are the Procedural Memory (`Productions'), Intentional Module, the Declarative Module, the Imaginal Module, the Manual Module and the Visual Module (see Fig. \ref{65}). These modules can be accessed via their corresponding buffers (Fig. \ref{65}). One buffer can always contain one piece of information called chunk. These can be mapped onto brain regions like anterior cingulate cortex for the goal buffer and basal ganglia for the procedural memory. Information in different buffers can be either compared or copied. For example, information can get into the visual buffer (from the outside), `A', for example. This information is remembered, which means copied to the working memory buffer (`problem state buffer') and stored in working memory (`Imaginal Module'). Additionally, the visual buffer chunk is copied to the declarative memory buffer to receive information about the letter `A'. Subsequently, the seen information can be typed into a keyboard by copying the `A' chunk into the manual buffer and requesting a hand movement to the letter `A'. 
\\
What runs an ACT-R model is the Procedural Memory. All its actions are expressed as IF-THEN statements. These are called production rules. At the beginning, the production rule with the IF that best fits the current state of the model is chosen. Subsequently, the according THEN-rule is fired. As an example for counting from 2 to 5, we need to set the goal chunk to `Count from 2 to 5'. Also, the Declarative Memory needs to provide the chunks with the order of the numbers. The production rules then guide the model through counting by firing the THEN - rules for `say the first number', `move to next number', `say next number', until `the number you just said was 5'.

\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/65}
\decoRule
\caption{ACT-R's modules and buffers. From the slides of Groningen Spring School for Cognitive Architectures, 2017.}
\label{65}
\end{figure}

In general, production rules can only happen serially, and also modules can handle only one request at a time and only have one chunk in their buffer. The different modules can operate in parallel. The retrieval time from declarative memory chunks can be modulated by `chunk activation', and by partial matching similar facts can be confused. The explanation of this would go beyond the scope of this introduction. If several production rules in procedural memory fit the current model state, the one with the highest utility is chosen (this is very similar to chunk activation in declarative memory). A production rule's utility depends on its previous usefulness, reward, time to reward, and noise. This way, also new production rules can be learned. 
\\
The time an action takes is always based on basic research findings. One example is that all motor actions are based on Fitt's law (\cite{fitts1954information}). Another is that production rules can only fire sequentially, and if several fit the current model state only one gets to fire. This is based on inhibitory projections from striatum to pallidum that inhibit all productions except for the chosen one. By this, only one action is executed at a time (\cite{graybiel1995building, salvucci2008threaded, anderson2004integrated}). Examples for behavior that has been successfully modeled by ACT-R can be found on http://act-r.psy.cmu.edu/publication/. Also driver behavior has before been modeled in ACT-R (\cite{salvucci2001toward, salvucci2006modeling}). Salvucci's driver model consists of four iterating production rules that adjust steering angle and acceleration. Production one and two find near and far point on the street to adjust the steering angle. Production three sends motor commands for steering and acceleration and directs visual attention to the far point. Production four checks for the stability of the car by lateral position and velocity. If the vehicle is unstable this process is immediately repeated, otherwise after a delay time. Situation awareness is build up by checking four areas (left lane, right lane, forward or backward) with equal probability. The model moves visual attention to that are and determines whether a vehicle is present. If that is the case, this is stored in working memory. After some time, the information in working memory of course decays and needs to be updated. Thus, also erroneous driver behavior is modeled and its causes explained. 

\subsection{Job Shop Scheduling}
In job shop scheduling, `resources' can execute `tasks' that are partly constrained in their order. The name comes from a `job shop': a manufacturing system in which machines are arranged and used in an order in which a task can be finished as fast as possible, depending on which machines can do which tasks and in which order they need to be done. Examples are job shops that make parts for industrial machinery, ships, airplanes, etc. Job shop scheduling in computer science is an optimization problem that organizes tasks in a way that the tasks are fulfilled as fast as possible. Its application goes far beyond that of a classical job shop. 
\\
In this thesis, the python job shop schedule implementation `Pyschedule' by Tim Nonner was used. As the core solver, the CP-solver from OR-tools was used. This is a Google optimization tool. This solver tries out all possible combinations of task order and resource assignment. If it reaches a solution that does not meet the constraints, it `unbounds' the variable, goes one step back in its search tree (`backtracking'), and tries the next variable. In the end, OR-tools outputs all solutions that meet the constraints. Pyschedule identifies the one that has the shortest makespan (=time until all tasks are done). 



\section{Aim of the thesis}
This thesis suggests, implements and validates two options to model takeover time. While one option is purely theoretical (Cognitive-Motor Driver Model), the other data-driven (Regression Analysis). In the end, both methods are compared with current literature and one another.






























