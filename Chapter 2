\chapter{A Cognitive-Motor LEGO Model} 

\label{Chapter2} 

\section{Model}

In \ref{Chapter1}, an overview about cognitive modeling and job job scheduling (and pyschedule) has been given. blabla that's how I combined the two and why. ACT-R long time to learn and for `simple' reaction time laboratory experiments. also for driving but only a very special case. downside: it cannot learn. fine for us because we assume drivers have learnt already. Kritik an ACT-R: schwer zu lernen, `when trying to model more complex tasks, such as driving, the serial processor of ACT-R causes bottlenekcs coincerning the speed of calulation (Marina). in Marina's diss anforderungen: 1)employs knowledge of detailed cognitive structure but simulate performance on higher level 2) with if-then rules 3)modular (easy to add and change) 4)normative and naturalistic driver behavior.  thats what were interested in.Actions of one module (=resource) can only happen successively, all actions of different modules can happen simultaneously. The procedural memory is the 'impulse generator' that orchestrates the actions of the other modules by production rule firing. Fig. \ref{tree} shows the following decision tree more graphically. It is important to note that the added tasks have nothing temporal about them; they only decide which `LEGO-packages' are added to the big LEGO-box out of which in the end the fastest possible solution is built.

The following modules (resources) are available:
\\
Cognitive Modules:
\begin{itemize}
\item
Procedural Memory;
\item
Working Memory;
\item
Declarative Memory;
\item
Visual Module;
\end{itemize}
Motor Modules:
\begin{itemize}
\item
Aural module;
\item 
Head module; 
\item
Eyes Module;
\item
Feet Module;
\item
Thorax Module
\end{itemize}

The input variables are:
\\
\begin{itemize}
\item
Expert - differentiates between a novice that listens to the whole takeover request before taking over, and someone who recognizes right after the first tone that he should take over;
\item
Lockout - determines whether the secondary task is automatically ended by in-car entertainment;
\item
Declarative Memory;
\item
Visual Module;
\end{itemize}
Motor Modules:
\begin{itemize}
\item
Aural module;
\item 
Head module; 
\item
Eyes Module;
\item
Feet Module;
\item
Thorax Module
\end{itemize}

Even though we are certain that extreme drowsiness has an influence on takeover time, we excluded it as an influencing variable. In that case, driving should not be allowed and the car should enter a minimal risk state rather than giving control to a drowsy driver. Also boredom was excluded, because its consequences can differentiate between a fast, overhasty takeover due to surprise, or a slow takeover. Cognitive demand is only asked as `yes' or `no' because it is hard to measure in more detail. Felt urgency of the situation is build upo by traffic, time budget and criticality of the scenario; but it is hard to measure. it would make the takeover faster...bei mehr traffic dauert es laenger!

we want a normative `driving school' takeover. 

The basic tasks of every take-over are described in the following. 

\subsection{Basic Takeover}
\subsubsection{Attend Aural}\label{prod}
The takeover begins with a production rule that commands the Aural module to encode the sound that is heard, see \ref{encodesound}. A production rule always takes 50ms in ACT-R (\cite{bothell2004act, anderson2009can}).

\subsubsection{Request Meaning Sound}
After the sound has been encoded, another production rule commands the procedural memory to retrieve the meaning of the sound from declarative memory. This is different than in e.g. (\cite{anderson2009can}), where the sound is only encoded and 'immediately' understood. Whereas the model by Anderson models behavior in a simple reaction time experiment, the complexity of the options what the sound could mean here requires the driver to remember what the sound means. In some cases, it will be a very long time ago that the driver was last requested to take over. 

\subsubsection{Meaning Sound}
Is done by the procedural memory. It takes 100ms. This is derived from the 50ms which a request takes if only one matching chunk is present in declarative memory \cite{bothell2016tut}. Another 50ms are added to choose the right chunk from several matching ones, because the sound will most likely not be the only possible sound with which the car requests some action from the driver. For simplicity, it is assumed that the driver always chooses the right chunk. Such a severe misunderstanding at the very beginning of the takeover would lead to the car entering a 'minimal risk state' (such as stopping the car on the hard shoulder), which makes modeling of driver behavior unnecessary.

\subsubsection{Change Goal}
This production rule commands a change of the goal buffer in ACT-R. A goal buffer representation did not seem to be helpful in my case (the goal would just be 'take over' during the whole takeover), but the time-consuming production rule was implemented.

\subsubsection{move Attention}
As the 'impulse generator', the procedural memory commands every move of attention (see \cite{salvucci2009toward, salvucci2008threaded} for examples). This happened already in the 'attend aural' command. It also precedes every saccade. In this case, it is requested that attention is moved to the road.
\label{moveAttention}


\begin{sidewaysfigure}
\centering
\includegraphics[width = 0.8\textwidth]{Figures/UntitledDiagram.pdf}
\decoRule
\caption{Decision tree of the model.}
\label{tree}
\end{sidewaysfigure}



In case the driver is not ready to take over, the following inputs can model the driver's changing state. 


\subsection{Lockout}
It has been observed that subjects take longer to disengage from a secondary task if the secondary task is not automatically quit by the in-car entertainment (\cite{}). 
\subsubsection{Quit Non-driving related task}
Therefore, another production rule that commands the disengagement from the non-driving related task. Opel finds 200ms longer of one has to manually end the NDRT? referenz?

\subsection{Expert}
Depending on whether the person that takes over is novice or expert, the task 'encode sound' has a different length. 

\subsubsection{Encode Sound}
A novice or someone who has not taken over for a very long time always listens to the whole output which takes five seconds. Thus, 'encode sound' takes five seconds. Someone who has experienced several Requests to Intervene (RtI) recently, 'encode sound' takes 1000ms. Thus, the warning tone for a critical scenario (e.g. avoidance of a crash) has to be different than the warning tone for an uncritical takeover (e.g. simply continuing to drive on a straight road). 
\label{encodesound}


\subsection{Gaze Off}
If the driver has his gaze off road, the following tasks are added:

\subsubsection{Motor Preparation Head}\label{prep}
In ACT-R, motor preparation time depends on the complexity of the movement and how different it is from the previous movement (\cite{bothell2004act, anderson2004integrated}). For simplicity, I will always use a motor preparation time of 250ms in my model, which corresponds to a typical motor preparation time in ACT-R (\cite{bothell2016tut}).

\subsubsection{Motor Initiation Head}\label{ini}
Like in ACT-R, every motor action is preceded by a 50ms initiation (\cite{bothell2004act}).

\subsubsection{Move Head}\label{head}
Movement times were, as in ACT-R, calculated by Fitt's law. The Index of Difficulty for head movement was calculated with $ID = \log _2 \left( \frac{2A}{W} \right)$. The main movement was assumed to be 90\textdegree (from co-driver seat to the road), the target size was assumed to be 18\textdegree. This is the area of the visual field that is covered by the fovea. The resulting movement time was taken from (\cite{hoffmann2017head}). In this case Index of Difficulty was 2, and the resulting movement time 600ms.

%The main movement was assumed to be 60\textdegree (from co-driver seat to the road), the target size was assumed to be 30\textdegree (the part of the wind shield that shows the relevant part of the road). The resulting movement time was taken from (\cite{hoffmann2017head}). In this case Index of Difficulty was 2, and the resulting movement time 600ms. 

\subsubsection{Move Attention}
see \ref{moveAttention} - maybe this one is too much?

\subsubsection{Eye Movement Preparation}\label{eyePrep}
As described in \cite{salvucci2001integrated}, every saccade is preceded by 135ms motor preparation.

\subsubsection{Saccade}\label{saccade}
As described in \cite{salvucci2001integrated}, every saccade consists of 50ms for non-labile programming (\cite{becker1979analysis}), 20ms for saccade execution, and 2ms are added for every degree of visual angle subtended by the saccade. For simplicity, I always assume 10 degrees, which results in a saccade time of 80ms. 

\subsubsection{Encode Visual Object}\label{encode}

With the equation given in \cite{salvucci2001integrated}, encoding time was calculated to be 85ms. This is based on the assumption that spatial frequency of the object is 0.2 and the visual angle 5\textdegree (the person nearly looks at the object already).

%With the equation given in \cite{salvucci2001integrated}, encoding time was calculated to be 135ms. This is based on the assumption that spatial frequency of the object is 0.5 and the visual angle 0 (the person already looks at the object). 

\subsection{Urgency}\label{prod}
We assume that from now on, the driver has a rough understanding of how urgent the takeover is. This is mainly influenced by the takeover request, the time budget he is given to take over, but also by the amount of surrounding traffic. he also knows because it takes about 30ms to have a general understand of a situation; whether it is urgent, depending on scenario and traffic situation \cite{oliva2006building}.From this point on, a production rule will take 50ms if the takeover is perceived as urgent, and 100ms if the situation is not perceived as urgent. The background of this is the following:
In ACT-R, each production rule has a utility value. This utility value is based on reinforcement learning and depends on its previous `usefulness' in the specific context (\cite{gunzelmann2011sleep}). 
auch noch erwaehnen: from edges to blobs: man hat sofort ein grobes verstaendinis in welcher situation man sich befindet.

\subsection{ Turn Body }
if the body needs to be turned back to the road, the following tasks are added:

\subsubsection{Thorax Motor Preparation}
With the same reasoning as for \ref{prep}, this takes 250ms. 

\subsubsection{Thorax Motor Initiation}
With the same reasoning as for \ref{ini}, this takes 50ms. 

\subsubsection{Thorax Turn}
in cite Befelein, a takeover takes 1 second longer when the driver is turned away during the takeover request. In [\cite{hoffmann2015movement}], a thorax movement with 60cm amplitude takes 400ms. Considering that our case is more complicated than in the trial (turning in the car is not as easy, and usually subjects adjust their seating after turning), 1 second seems a suitable time. 

\subsection{Unoccupy Hands}
In case the driver's hands are occupied, the item needs to be dropped (assumed on the co-driver seat) before the hands can be moved to the steering wheel. See \ref{prod}

\subsubsection{Request Unoccupy Hands}
A production rule that requests the shift of attention to dropping whatever is in the driver's hand to the co-driver seat. 

\subsubsection{Move Attention}
A production rule that initiates head, hand and eye movement to the co-driver seat.

\subsubsection{Head to Co-driver seat}
Movement time of the head as in \ref{head}.

\subsubsection{Eye Movement Preparation}
See \ref{eyePrep}.

\subsubsection{Saccade}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Drop Item}
With the distance of the Hands, it is calculated with Fitt's law for Hand movement how long the movement will take. The same equation as in ACT-R is used: $MovementTime = 100 \cdot \log_2 \left( \frac{(DistanceHands)}{TargetSize} + 0.5\right)$ [\cite{bothell2004act}]. If the takeover scenario is critical, the target size (=area where the item is dropped) is 40cm, because the driver is assumed to drop the item just anywhere as fast as possible. In an uncritical scenario, the target area is 20cm, because the driver is assumed to put the item to a certain place (e.g. a newspaper to the box(Fach?) in the side door). 

\subsubsection{Move Attention}
A production rule that requests head, hand and eye movement back to the street.

\subsubsection{Head To Road}
Movement time of the head as in \ref{head}.

\subsubsection{Eye Movement Preparation}
See \ref{eyePrep}.

\subsubsection{Saccade}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsection{Hands To Wheel}

\subsubsection{Request Hands to Wheel}
A production rule that requests the shift of attention to moving the hands to the wheel. See [\ref{prod}].

\subsubsection{Hands Motor Preparation}
See \ref{prep}.

\subsubsection{Hands Motor Initiation}
See \ref{ini}

\subsubsection{Hands To Wheel}
With the distance of the Hands, it is calculated with Fitt's law for Hand movement how long the movement will take. The same equation as in ACT-R is used: $MovementTime = 100 \cdot \log_2 \left( \frac{(DistanceHands)}{TargetSize} + 0.5\right)$ [\cite{bothell2004act}]. Target size was measured as 10cm, the distance of the hands is given as input into the model. 

\subsection{Feet To Pedals}

\subsubsection{Request Move Feet}
Production rule that requests the movement of the feet to the pedals (gas and clutch) of the car.

\subsubsection{Feet Motor Preparation}
See \ref{prep}.

\subsubsection{Feet Motor Initiation}
See \ref{ini}.

\subsubsection{Move Feet}
The time for foot movement is 180ms, as in[\cite{morrison1986movement}]. 

\subsection{Check Road}
This part happens for every takeover, independent of input parameters.

\subsubsection{Check Near Point}
Production rule that requests to check the `near point' of the road. This concept is taken from Salvucci's driver model [\cite{salvucci2006modeling}].

\subsubsection{Saccade to Near Point}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.


\subsubsection{Check Far Point}
Production rule that requests to check the `far point' of the road. This concept is taken from Salvucci's driver model [\cite{salvucci2006modeling}].

\subsubsection{Saccade to Far Point}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Curvature}\label{wm}
From the information of near and far point, the model knows the curvature of the road. If the far point is straight over the near point, the curvature is zero. This information is stored in the working memory module. The default time for building such a representation (thus, before the chunk is built and put into working memory) is 200ms in ACT-R [\cite{bothell2016tut}]. 


\subsection{Takeover In Noncritical Situation}
In a noncritical situation, the driver is expected to take over driving on a straight road without any hazards. Thus, he only needs to take back control without any further action required. Thus, the following tasks are added :

\subsubsection{Request Lever Pull}
A production rule that requests the hands to move towards and pull the lever that deactivates the automation mode.

\subsubsection{Feet Motor Preparation}
See \ref{prep}.

\subsubsection{Feet Motor Initiation}
See \ref{ini}.

\subsubsection{Pull Lever}
We assume that the lever pull can be compared to a key press in ACT-R. It takes 100ms [\cite{bothell2004act}].

\subsection{Takeover in a Critical Situation}
In a critical situation, we assume that either the road is blocked, the car deviates from the lane due to a wind gust, the takeover is requested in a curve, or any other circumstances require more complex action. Thus, simply deactivating the automation is not sufficient. The driver most likely will check whether it is possible to change lanes in case of an obstacle, and needs to have knowledge of his surroundings for all of the critical cases. This is only the case if there is surrounding traffic. Then, we model gazes to back mirror, side mirror and back to the road. We assume the `worst case' that swerving is not possible and reaction time plus brake time need to be over before reaching an obstacle. If there is no traffic, we assume the driver to already know this from the first'gist' of the scene \cite{oliva2006building}. Then, the driver does not look into the mirro but only brakes as soon as he has noticed the curvature of the road.

\subsubsection{Request Check Rearward Mirror}
A production rule.

\subsubsection{Move Head To Rearward Mirror}
Since the head was moving already, motor preparation and initiation were omitted. Head movement was calculated to be 580ms with a 40\textdegree movement to the target and 10\textdegree target size. This was estimated by measures taken inside a car. 

\subsubsection{Saccade To Rearward Mirror}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Visual Object}
See \ref{wm}


\subsubsection{Request Check Side Mirror}
A production rule.

\subsubsection{Move Head To Side Mirror}
Head movement was calculated to be 710ms with a 100\degree movement to the target and 10\degree target size. This was estimated by measures taken inside a car.

\subsubsection{Saccade To Side Mirror}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Visual Object}
See \ref{wm}


\subsubsection{Request Gaze Back On Road}
A production rule.

\subsubsection{Move Head Back To Road}
Head movement was calculated to be 580ms with a 40\degree movement to the target and 10\degree target size. This was estimated by measures taken inside a car. 

\subsubsection{Saccade Back To Road}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Request Surroundings Traffic from Working Memory}
A production rule.

\subsubsection{Brake Time}
This is set to zero to compare the output time of the model with what is given as takeover time in literature and our own trials. When applied, the model should be changed to calculate brake time here (Velocity is already an input to the model; a commented line of code gives the equation for brake time). 

\subsection{Example model}
Fig.  shows the simplest takeover model in an uncritical situation:


\subsection{Output}
It draws from a weibull distribution with the mean we found and a bla...
damit habe ich es wie in act-r auch stochastisch gemacht
statt vorlauf bis feuern zu variierein durch utility ist bei mir einfach die länge des tasks unterschiedlich (task parameter) was ja aufs gleiche rauskommt
mean is shape paraemter plus location parameter. Like in Reichle, I used a gaussian to draw the data. 3 als shape-parameter wie in \cite{derichs1998vergleich, whelan2008effective}.




%in anpassung an boschdaten:
%turnSA rausgenommen weil es zu lang dauert mit den ganzen vielen saccaden
%- encode sound kürzer weil die das ja schon erwarten
%- change goal immer gleichlang (unabhängig von workload) - dafür je nach workload move attention 400ms lang wegen niedriger utility
%- wenn dangerous move head nur 300ms
%- ansonsten bleibt es bei den 600 aus dem paper
%- to wheel bekommt zusätzlich zu fitts law noch 600ms dazu weil die sich nicht eilig und nicht so zielgerichtet bewegen
%- head2coseat und zurück dauert normale 600 bei not urgent und 300 bei urgent
%- wenn gefährlich drop mit fitts law, ansonsten noch plus 600ms.
%- wenn urgent production rule check near 50, ansonsten 160ms.
%- wenn es gefährlich ist und mental workload hoch dauert check side back und road 400ms wegen utility, sonst 50ms. 
%- wenn gefährlich mehr traffic heißt mehr saccaden
%- eyemove prep reingemacht bei salvucci sccaden
%- lever press takes 200 instead of 100
%- noch eine saccade rein wenn man hände am lever hat aber noch nicht gepresst (aus video)
%SA komplett rausgelassen!

\section{Results}

\begin{figure}
\centering
\includegraphics[width = 0.5\textwidth]{Figures/36}
\decoRule
\caption{Model prediction in comparison to data.}
\label{18}
\end{figure}

\begin{figure}
\centering
\includegraphics[width = 0.5\textwidth]{Figures/35}
\decoRule
\caption{Model prediction in comparison to our data.}
\label{35}
\end{figure}

\begin{figure}
\centering
\includegraphics[width = 0.5\textwidth]{Figures/44}
\decoRule
\caption{Model prediction in comparison to literature data.}
\label{44}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/37}
        \caption{Part 1}
        \label{fig:gull}
    \end{subfigure}
 
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/38}
        \caption{Part 2}
        \label{fig:tiger}
    \end{subfigure}
 
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/39}
        \caption{Part 3}
        \label{fig:mouse}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/40}
        \caption{Part 4}
        \label{fig:gull}
    \end{subfigure}
    \caption{Jobshop Schedule of the takeover-tasks, part 1}
    \end{figure}
    
    \begin{figure}
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/41}
        \caption{Part 5}
        \label{fig:tiger}
    \end{subfigure}
 
    \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/42}
        \caption{Part 6}
        \label{fig:mouse}
    \end{subfigure}
    
        \begin{subfigure}[b]{1\textwidth}
        \includegraphics[width=\textwidth]{Figures/43}
        \caption{Part 7}
        \label{fig:gull}
    \end{subfigure}
    \caption{Jobshop Schedule of the takeover-tasks, part 2}\label{job}
\end{figure}



The mean predicted for the baseline condition is 2,61 seconds, for listening to an audiobook is 2,75s, playing tetris 2,51, reading a magazine 4,74 and searching something on the rear bench seat also 4,74. For gantt charts of each task with its input vector, see Figure ref . We compared the 34 results for all five conditions each with each predicted mean, see Fig. \ref{36}. This results in an $R^2$ of 0.217, which means that our model predicts 21.7\% of the variance in the data. The Mean Squared Error was 2.7. If we compare the means of the data with the predicted mean of the model,  $R^2$ is 0.96. If we draw from a Weibull-distribution for our prediction, the histograms of prediction and data can be found in \ref{35} (alte fig!).

For literature, I can only compare means to means. I chose the papers of Befelein and Gold to compare to my model, because they both tested as much as possible the circumstances that we input in out model. the only difference is that they have critical scenarios, and that they use a driving simulator. The takeover times given in each condition of the paper compared to the model prediction can be found in table bla. Rsqzare is 0.64. In general, my model predict too long takeover times compared to literature. this is because literature counts the takeover that happened overhasty or even ended in a crash. since we want to model a normative model, this is not gewuenscht. in Fig. \ref{44} we can see the comparison of the means of the literature and the LEGO-model.

\section{Discussion}

- problem vergleich mit literatur: die haben qulatität und zeit untershcielich gemessen  - in zeit sind übernahmen mit crash drin.
- wir bekommen rsquared schlehcter raus weil wir nur gegen ein und den gleichen mean vergleichen und rsquare auch die varianz vergleicht und wir keine haben; wenn ich allerdings gegen verteilung vergleiche wird es noch schlechter weil ja pro kondition ein größerer wert nichts zu sagen hat und nicht dadurch das vorhergesagte auch groeser wird; wenn ich means vergleiche bekomme ich rsquare von 96\% raus.





























