\chapter{A Cognitive-Motor Driver Model} 

\label{Chapter3} 

\section{Introduction}

While ACT-R works great to realistically model experiments that occur in an experimental setup, it is rarely used to model complex human behavior. A noteworthy example is \cite{salvucci2006modeling}. Unfortunately, learning and correctly coding complex behavior in ACT-R takes is meticulous work and certainly takes longer than six months. Another reported problem about ACT-R is its slow speed of calculation for complex task. \cite{plavvsic2010analysis} sets several requirements for modeling driver behavior: it should 1) employ knowledge of detailed cognitive structure but simulate performance on higher level 2) run with if-then rules 3) be modular (easy to add and change) and 4) reflect normative and naturalistic driver behavior . We met those requirements and overcame problems of programming difficulties and long running time by combining the theoretical background of ACT-R with job shop scheduling. This was done by using ACT-R's modules as `resources' in Pyschedule, and all of ACT-R's actions of the different modules as `tasks'. As for the order constraints in Pyschedule, we set as many as necessary and as little as possible constraints regarding task order for modeling a realistic takeover. In principle, this model thus works very similar to an ACT-R model. One important difference is that it cannot model learning. For our use case, this is acceptable because we assume to model a takeover-trained driver. 
\\
As in every Pyschedule and ACT-R program, actions of one module can only happen successively, while all actions of different modules can happen simultaneously. The procedural memory is the 'impulse generator' that orchestrates the actions of the other modules by production rule firing. For every takeover situation, it needs to be decided which actions are included into the model and which ones are not. For example, when modeling a takeover where the subject has his gaze on the road already, a head movement towards the road does not need to be modeled anymore. Fig. \ref{tree} shows the following decision tree more graphically.  It is important to note that the added actions have nothing temporal about them; they only decide which actions are added to the collection of actions out of which in the end the fastest possible solution is built. An example of the simplest possible takeover model can be found in Fig. \ref{gantt}.

\section{Method}

Inspired by the modules that are typically postulated within ACT-R, the following modules are considered important for modeling a takeover-scenario:
\\
Cognitive Modules:
\begin{itemize}
\item
Procedural Memory
\item
Working Memory
\item
Declarative Memory
\item
Visual Module
\end{itemize}
Motor Modules:
\begin{itemize}
\item
Aural module
\item 
Head module
\item
Eyes Module
\item
Feet Module
\item
Thorax Module\\
\end{itemize}
Takeover time is modulated by several variables. For example, a driver most likely takes longer for a takeover if he first has to turn back towards the road. The following modulating variables can be determined in the model:
\\
\begin{itemize}
\item
Expert (yes/no) - differentiates between a novice that listens to the whole takeover request before taking over, and someone who immediately recognizes the takeover request
\item
Gaze Off (yes/no) - whether the driver looks towards the street or elsewhere at the takeover request
\item
Long Gaze (yes/no) - duration of the current off- or on-road gaze. If the driver just looked away from the road, he does not need to build up situation awareness anymore
\item
Body Turned (yes/no) - whether the driver has his body turned away from the steering wheel or not
\item
Lockout (yes/no) - determines whether the secondary task is automatically terminated by in-car entertainment
\item
Hands Occupied (yes/no) - whether the driver's hands are occupied
\item
Distance Hands (yes/no) - how far the hands are away from the steering wheel
\item
Feet on Pedals (yes/no) - whether the feet are on gas pedal and clutch
\item 
Dangerous Scenario (yes/no) - whether the situation in which the driver needs to take over is dangerous / critical or not
\item
Driving Speed (km/h) - this is only needed for calculating the brake time in case of a dangerous scenario
\item
Low Time Budget (yes/no) - whether the driver has only little time to take over control
\item
Mental Workload (yes/no) - whether the driver was mentally distracted during the takeover request
\item
Traffic (yes/no) - whether there was traffic around or not
\end{itemize}

Even though we are certain that extreme drowsiness has an influence on takeover time, we excluded it as an influencing variable. In that case, driving should not be allowed and the car should enter a minimal risk state rather than giving control to a drowsy driver. Also boredom was excluded, because its consequences can vary between a fast, overhasty takeover due to surprise, or a slow takeover. Cognitive demand is only asked as `yes' or `no' because it is hard to measure in more detail.  

\subsection{Basic Takeover}
We will model a normative `driving school' takeover. 

The basic tasks of every take-over are described in the following.
\subsubsection{Attend Aural}\label{prod}
The takeover begins with a production rule that commands the Aural module to encode the sound that is heard, see \ref{encodesound}. A production rule always takes 50ms in ACT-R, which we adopted for our model (\cite{bothell2004act, anderson2009can}).

\subsubsection{Request Meaning Sound}
After the sound has been encoded, another production rule commands the procedural memory to retrieve the meaning of the sound from declarative memory. This is different than in e.g. (\cite{anderson2009can}), where the sound is only encoded and 'immediately' understood. Whereas the model by Anderson models behavior in a simple reaction time experiment, the complexity of the options what the sound could mean here requires the driver to remember what the sound means. In some cases, it will be a very long time ago that the driver was last requested to take over. 

\subsubsection{Meaning Sound}
Is done by the procedural memory. It takes 100ms. This is derived from the 50ms which a request takes if only one matching chunk is present in declarative memory \cite{bothell2016tut}. Another 50ms are added to choose the right chunk from several matching ones, because the sound will most likely not be the only possible sound with which the car requests some action from the driver. For simplicity, it is assumed that the driver always chooses the right chunk. Such a severe misunderstanding at the very beginning of the takeover would lead to the car entering a 'minimal risk state' (such as stopping the car on the hard shoulder), which makes modeling of driver behavior unnecessary.

\subsubsection{Change Goal}
This production rule commands a change of the goal buffer in ACT-R. A goal buffer representation did not seem to be helpful to implement, since the goal would just be 'take over' during the whole takeover. Therefore, only the time-consuming production rule was implemented.

\subsubsection{Move Attention}
As the 'impulse generator', the procedural memory commands every move of attention (see \cite{salvucci2009toward, salvucci2008threaded} for examples). This happened already in the 'attend aural' command. It also precedes every saccade. In this case, it is requested that attention is moved to the road.
\label{moveAttention}


\begin{sidewaysfigure}
\centering
\includegraphics[width = 1\textwidth]{Figures/UntitledDiagram.jpg}
%\decoRule
\caption{Flow diagram to determine required actions depending on the model input variables.}
\label{tree}
\end{sidewaysfigure}



In case the driver is not ready to take over, the following inputs can model the driver's changing state. 


\subsection{Lockout}
It has been observed that subjects take longer to disengage from a secondary task if the secondary task is not automatically quit by the in-car entertainment (\cite{opel}). 
\subsubsection{Quit Non-driving related task}
Therefore, another production rule is required that commands the disengagement from the non-driving related task.

\subsection{Expert}
Depending on whether the person that takes over is novice or expert, the action 'encode sound' has a different length. 

\subsubsection{Encode Sound}
A novice or someone who has not taken over for a very long time always listens to the whole output which takes five seconds. Thus, 'encode sound' takes five seconds. Someone who has experienced several Requests to Intervene (RtI) recently, 'encode sound' takes 1000ms. Thus, the warning tone for a critical scenario (e.g. avoidance of a crash) has to be different than the warning tone for an uncritical takeover (e.g. simply continuing to drive on a straight road). 
\label{encodesound}


\subsection{Gaze Off}
If the driver has his gaze off road, the following tasks are added:

\subsubsection{Motor Preparation Head}\label{prep}
In ACT-R, motor preparation time depends on the complexity of the movement and how different it is from the previous movement (\cite{bothell2004act, anderson2004integrated}). For simplicity, I will always use a motor preparation time of 250ms in my model, which corresponds to a typical motor preparation time in ACT-R (\cite{bothell2016tut}).

\subsubsection{Motor Initiation Head}\label{ini}
Like in ACT-R, every motor action is preceded by a 50ms initiation (\cite{bothell2004act}).

\subsubsection{Move Head}\label{head}
Movement times were calculated by Fitt's law (\cite{fitts1954information}). The Index of Difficulty for head movement was calculated with $ID = \log _2 \left( \frac{2A}{W} \right)$. The main movement was assumed to be 90\textdegree (from co-driver seat to the road), the target size was assumed to be 18\textdegree. This is the area of the visual field that is covered by the macula. The resulting movement time was taken from (\cite{hoffmann2017head}). In this case Index of Difficulty was 2, and the resulting movement time 600ms.

%The main movement was assumed to be 60\textdegree (from co-driver seat to the road), the target size was assumed to be 30\textdegree (the part of the wind shield that shows the relevant part of the road). The resulting movement time was taken from (\cite{hoffmann2017head}). In this case Index of Difficulty was 2, and the resulting movement time 600ms. 

\subsubsection{Move Attention}
A production rule - see \ref{moveAttention}.

\subsubsection{Eye Movement Preparation}\label{eyePrep}
As described in \cite{salvucci2001integrated}, every saccade is preceded by 135ms motor preparation.

\subsubsection{Saccade}\label{saccade}
As described in \cite{salvucci2001integrated}, every saccade consists of 50 ms (\cite{becker1979analysis}), 20 ms for saccade execution, and 2ms are added for every degree of visual angle subtended by the saccade. For simplicity, I always assume 10 degrees, which results in a saccade time of 80 ms. 

\subsubsection{Encode Visual Object}\label{encode}

With the equation given in \cite{salvucci2001integrated}, encoding time was calculated to be 85ms. This is based on the assumption that spatial frequency of the object is 0.2 and the visual angle 5\textdegree (the person nearly looks at the object already).

%With the equation given in \cite{salvucci2001integrated}, encoding time was calculated to be 135ms. This is based on the assumption that spatial frequency of the object is 0.5 and the visual angle 0 (the person already looks at the object). 

\subsection{Urgency}\label{urgent}
We assume that from now on, the driver has a rough understanding of how urgent the takeover is. This is mainly influenced by the takeover request, the time budget he is given to take over, and the amount of surrounding traffic. Additionally, it takes 30 ms to have a general understanding of a scene, according to \cite{thorpe1996speed}. From this point on, a production rule will take 50ms if the takeover is perceived as urgent, and 100ms if the situation is not perceived as urgent. The background of this is the following:
In ACT-R, each production rule has a utility value. This utility value is based on reinforcement learning and depends on its previous `usefulness' in the specific context (\cite{gunzelmann2011sleep}). In case there are several production rules that fit the current model state, the production rule with the highest utility value gets to fire. In general, only production rules with a utility higher than a certain threshold can fire. This threshold depends on a person's motivation. Thus, if the motivation to take over is low (the takeover is not urgent), the utility threshold is high and it takes longer until a production rule is selected. If a person rushes, the selection threshold is low and production rules are selected faster (and more likely erroneously) (\cite{reddi2000influence}). 

\subsection{ Turn Body }
If the body needs to be turned back to the road, the following tasks are added:

\subsubsection{Thorax Motor Preparation}
With the same reasoning as for \ref{prep}, this takes 250ms. 

\subsubsection{Thorax Motor Initiation}
With the same reasoning as for \ref{ini}, this takes 50ms. 

\subsubsection{Thorax Turn}
In \cite{befelein2016}, a takeover takes one second longer when the driver is turned away during the takeover request. In \cite{hoffmann2015movement}, a thorax movement with 60cm amplitude takes 400ms. Considering that our case is more complicated than in their experiment (turning in the car is not as easy and usually subjects adjust their seating after turning), one second seems a suitable time. 

\subsection{Unoccupy Hands}
In case the driver's hands are occupied, the item needs to be dropped (assumed on the co-driver seat) before the hands can be moved to the steering wheel. See section \ref{prod}

\subsubsection{Request Unoccupy Hands}
A production rule that requests the shift of attention to dropping whatever is in the driver's hand to the co-driver seat. 

\subsubsection{Move Attention}
A production rule that initiates head, hand and eye movement to the co-driver seat.

\subsubsection{Head to Co-driver seat}
Movement time of the head as in \ref{head}.

\subsubsection{Eye Movement Preparation}
See \ref{eyePrep}.

\subsubsection{Saccade}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Drop Item}
The duration of this action is again calculated by Fitt's law, adapted for the the distance of the Hands. The same equation as in ACT-R is used: $MovementTime = 100 \cdot \log_2 \left( \frac{(DistanceHands)}{TargetSize} + 0.5\right)$ (\cite{bothell2004act}). If the takeover scenario is critical, the target size (=area where the item is dropped) is 40cm, because the driver is assumed to drop the item just anywhere as fast as possible. In an uncritical scenario, the target area is 20cm, because the driver is assumed to put the item to a certain place (e.g. a newspaper to the box in the side door). 

\subsubsection{Move Attention}
A production rule that requests head, hand and eye movement back to the street.

\subsubsection{Head To Road}
Movement time of the head as in \ref{head}.

\subsubsection{Eye Movement Preparation}
See \ref{eyePrep}.

\subsubsection{Saccade}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsection{Hands To Wheel}

\subsubsection{Request Hands to Wheel}
A production rule that requests the shift of attention to moving the hands to the wheel. See \ref{prod}.

\subsubsection{Hands Motor Preparation}
See \ref{prep}.

\subsubsection{Hands Motor Initiation}
See \ref{ini}

\subsubsection{Hands To Wheel}
With the distance of the Hands, it is calculated with Fitt's law for Hand movement how long the movement will take. The same equation as in ACT-R is used: $MovementTime = 100 \cdot \log_2 \left( \frac{(DistanceHands)}{TargetSize} + 0.5\right)$ [\cite{bothell2004act}]. Target size was measured as 10cm, the distance of the hands is given as input into the model. 

\subsection{Feet To Pedals}

\subsubsection{Request Move Feet}
Production rule that requests the movement of the feet to the pedals (gas and clutch) of the car.

\subsubsection{Feet Motor Preparation}
See \ref{prep}.

\subsubsection{Feet Motor Initiation}
See \ref{ini}.

\subsubsection{Move Feet}
The time for foot movement is 180ms, as in \cite{morrison1986movement}. 

\subsection{Check Road}
This part happens for every takeover, independent of input parameters.

\subsubsection{Check Near Point}
A production rule that requests to check the `near point' of the road. This concept is taken from Salvucci's driver model (\cite{salvucci2006modeling}).

\subsubsection{Saccade to Near Point}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.


\subsubsection{Check Far Point}
Production rule that requests to check the `far point' of the road. This concept is taken from Salvucci's driver model (\cite{salvucci2006modeling}).

\subsubsection{Saccade to Far Point}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Curvature}\label{wm}
From the information of near and far point, the model knows the curvature of the road. If the far point is straight over the near point, the curvature is zero. This information is stored in the working memory module. The default time for building such a representation (thus, before the chunk is built and put into working memory) is 200ms in ACT-R (\cite{bothell2016tut}). 


\subsection{Takeover In Noncritical Situation}
In a noncritical situation, the driver is expected to take over driving on a straight road without any hazards. Thus, he only needs to take back control without any further action required. Thus, the following tasks are added :

\subsubsection{Request Lever Pull}
A production rule that requests the hands to move towards and pull the lever that deactivates the automation mode.

\subsubsection{Feet Motor Preparation}
See \ref{prep}.

\subsubsection{Feet Motor Initiation}
See \ref{ini}.

\subsubsection{Pull Lever}
We assume that the lever pull can be compared to a key press in ACT-R. It takes 100ms (\cite{bothell2004act}).

\subsection{Takeover in a Critical Situation}
In a critical situation, we assume that either the road is blocked, the car deviates from the lane due to a wind gust, the takeover is requested in a curve, or any other circumstances that require more complex action. Thus, simply deactivating the automation is not sufficient. The driver most likely will check whether it is possible to change lanes in case of an obstacle, and needs to have knowledge of his surroundings. This is only the case if there is surrounding traffic. In that case, we model gazes to back mirror, side mirror and back to the road. We assume the `worst case' that swerving is not possible and reaction time plus brake time need to be over before reaching an obstacle. If there is no traffic, we assume the driver to already know this from the first 'gist' of the scene \cite{oliva2006building}. Then, the driver does not look into the mirror but only brakes as soon as he has noticed the curvature of the road.

\subsubsection{Request Check Rearward Mirror}
A production rule.

\subsubsection{Move Head To Rearward Mirror}
Since the head was moving already, motor preparation and initiation were omitted. Head movement was calculated to be 580ms with a 40\textdegree movement to the target and 10\textdegree target size. This was estimated by measures taken inside a car. 

\subsubsection{Saccade To Rearward Mirror}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Visual Object}
See \ref{wm}


\subsubsection{Request Check Side Mirror}
A production rule.

\subsubsection{Move Head To Side Mirror}
Head movement was calculated to be 710ms with a 100\textdegree movement to the target and 10\textdegree target size. This was estimated by measures taken inside a car.

\subsubsection{Saccade To Side Mirror}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Remember Visual Object}
See \ref{wm}


\subsubsection{Request Gaze Back On Road}
A production rule.

\subsubsection{Move Head Back To Road}
Head movement was calculated to be 580ms with a 40\textdegree movement to the target and 10\textdegree target size. This was estimated by measures taken inside a car. 

\subsubsection{Saccade Back To Road}
See \ref{saccade}.

\subsubsection{Encode Visual Object}
See \ref{encode}.

\subsubsection{Request Surroundings Traffic from Working Memory}
A production rule.

\subsubsection{Brake Time}
This is set to zero to compare the output time of the model with what is given as takeover time in literature and our own trials. When applied, the model should be changed to calculate brake time here (Velocity is already an input to the model; a commented line of code gives the equation for brake time). 

\subsection{Example model}
Fig. \ref{gantt} shows the simplest takeover model in an uncritical situation.


\subsection{Output}
With these tasks, pyschedule then organizes the tasks in a way that the they are done as fast as possible while fulfilling the constraints of order and one task per module. Thus, for every takeover situation (=combination of input variables), pyschedule outputs exactly the same time. This is not realistic, because some people take longer and some shorter for taking over for reasons that are not captured by our model. Typically, reaction times are distributed in a skewed Weibull-distribution: There is one threshold under which it is impossible to react, most people take slightly longer than that threshold, and some are much slower. In ACT-R, this stochasticity is realized by different utilities for tasks. The higher the utility, the faster the rule is chosen to fire. In our model, we reach stochasticity by setting pyschedule's output as mean of a Weibull distribution. The distribution's shape parameter was set to 3. This has been found to be a typical reaction time distribution shape (\cite{derichs1998vergleich, whelan2008effective}).
%wäre es nicht richtiger unser output als minimum zu setzen??






%in anpassung an boschdaten:
%turnSA rausgenommen weil es zu lang dauert mit den ganzen vielen saccaden
%- encode sound kürzer weil die das ja schon erwarten
%- change goal immer gleichlang (unabhängig von workload) - dafür je nach workload move attention 400ms lang wegen niedriger utility
%- wenn dangerous move head nur 300ms
%- ansonsten bleibt es bei den 600 aus dem paper
%- to wheel bekommt zusätzlich zu fitts law noch 600ms dazu weil die sich nicht eilig und nicht so zielgerichtet bewegen
%- head2coseat und zurück dauert normale 600 bei not urgent und 300 bei urgent
%- wenn gefährlich drop mit fitts law, ansonsten noch plus 600ms.
%- wenn urgent production rule check near 50, ansonsten 160ms.
%- wenn es gefährlich ist und mental workload hoch dauert check side back und road 400ms wegen utility, sonst 50ms. 
%- wenn gefährlich mehr traffic heißt mehr saccaden
%- eyemove prep reingemacht bei salvucci sccaden
%- lever press takes 200 instead of 100
%- noch eine saccade rein wenn man hände am lever hat aber noch nicht gepresst (aus video)
%SA komplett rausgelassen!

\section{Results}

\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/36}
\decoRule
\caption{Model prediction in comparison to literature data.}
\label{36}
\end{figure}

\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/63}
\decoRule
\caption{Model prediction in comparison to our data.}
\label{35}
\end{figure}

\begin{figure}
\centering
\includegraphics[width = 0.7\textwidth]{Figures/44}
\decoRule
\caption{Model prediction in comparison to literature data.}
\label{44}
\end{figure}


\begin{sidewaysfigure}
\centering
\includegraphics[width = 1\textwidth]{Figures/gantt.jpg}%groesser machen und zentrieren und schift direkt drunter (zum jpg machen)
%\decoRule
\caption{Decision tree of the model.}
\label{gantt}
\end{sidewaysfigure}

\begin{table}
 \centering
  \begin{tabular}{ c | c | c | c | c | c | c }
    \hline
    
     &                        Reference & &        Audiobook &  &       Searching Task & \\ \hline
      &                        Data & Prediction & Data & Prediction & Data & Prediction \\ \hline
      Median              & 2.71 & 2.56&        3.1 &    2.82 &         4.9 & 4.85 \\ \hline
      75\% percentile & 3.33 & 3.44 &       3.91 &   3.72 &        6.4 & 5.73\\ \hline
      95\% percentile & 4.4 & 5.8 &          6.59 & 6       &         8.9 & 8 \\ \hline
       & & & & & & \\ \hline
       & Read & & Tetris \\ \hline
      &Data & Prediction & Data & Prediction\\ \hline
     Median& 4.76 & 4.85& 3.1 & 3.56 \\ \hline
     75\% percentile & 6.5 & 5.7 &4.1 & 4.38  \\ \hline
     95\% percentile & 9.4 & 8.26 & 7.19 & 6.83   \\ \hline
    
  \end{tabular}
 \caption{Predicted takeover times}
\end{table}\label{cases}

\begin{table}
 \centering
  \begin{tabular}{ c | c | c | c | c | c }
    \hline
    
    Input & Baseline & Audiobook & Tetris & Reading & Searching Task \\ \hline
     Expert&0&0&1&1&1 \\ \hline
     Gaze Off& 1&1&1&1&1\\ \hline
     Long Gaze& 1&1&1&1&1\\ \hline
     Body Turned&0 &0&0&0&1\\ \hline
     Lockout&1&1&0&0&0 \\ \hline
     Hands Occupied&0&0&0&1&1 \\ \hline
     Distance Hands&30&30&30&60&60\\ \hline
     Feet On Pedals&0&0&0&0&0  \\ \hline
     Dangerous Scenario&0&0&0&0&0 \\ \hline
     Driving Speed&120&120&120&120&120 \\ \hline
     Perceived Urgency&0&0&0&0&0\\ \hline
     Mental Workload&0&1&1&1&1\\ \hline
     Traffic&1&1&1&1&1\\ \hline
    
  \end{tabular}
 \caption{Input for each condition}
\end{table}\label{input}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{55.jpg}
        \caption{Data}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{58.png}
        \caption{Model}
    \end{subfigure}
    \caption{Comparison of experimental data with data predicted by the model for the Baseline condition.}\label{55}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{56.jpg}
        \caption{Data}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{61.png}
        \caption{Model}
    \end{subfigure}
    \caption{Comparison of experimental data with data predicted by the model for the Reading condition}\label{56}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{57.jpg}
        \caption{Data}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{60.png}
        \caption{Model}
    \end{subfigure}
    \caption{Comparison of experimental data with data predicted by the model for the Tetris condition}\label{57}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{53.jpg}
        \caption{Data}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{59.png}
        \caption{Model}
    \end{subfigure}
    \caption{Comparison of experimental data with data predicted by the model for the Audiobook condition}\label{58}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{54.jpg}
        \caption{Data}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.4\textwidth}
        \includegraphics[width=\textwidth]{62.png}
        \caption{Model}
    \end{subfigure}
    \caption{Comparison of experimental data with data predicted by the model for the Searching condition}\label{59}
\end{figure}

The model predicts a mean of 2.61 seconds for the baseline condition, for listening to an audiobook it is 2.75s, playing tetris 2.51, reading a magazine 4.74 and searching something on the rear bench seat also 4.74 (see Table \ref{cases} for 75 and 95 percentiles). For an example job-shop schedule of the baseline condition, see Figure \ref{gantt} . The input vectors to each of the conditions can be found in Table \ref{input} . We compared the 34 results for all five conditions with each predicted mean, see Fig. \ref{36}. This results in an $R^2$ of 0.217, which means that our model predicts 21.7\% of the variance in the data. The Mean Squared Error was 2.7. If we compare the means of the data with the predicted mean of the model,  $R^2$ is 0.96. If we draw from a Weibull-distribution for our prediction, the histograms of prediction and data can be found in \ref{35}, \ref{55},\ref{56},\ref{57},\ref{58},\ref{59}. This results in an $R^2$ of 0.36.

grnauer erklären wie ich auf 36\%predicition vom cognitivem mdel hinbekomme - ich gehe davon aus wer schneller und wer langsamer typ ist

For literature, means can only be compared to means. The papers of \cite{befelein2016} and \cite{gold2016taking} were compared to the cognitive-motor-model, because they both tested  the circumstances that we input in our model. One difference is that they have critical scenarios, and that they use a driving simulator. The takeover times given in each condition of the paper compared to the model prediction can be found in Table \ref{comlit}. $R^2$ is 0.64.  In Fig. \ref{44} we can see the comparison of the means of the literature and the Driver model.

\section{Discussion}
In general, the model predicts too long takeover times compared to literature. This is because in literature, takeover that happened overhasty or even ended in a crash are considered. We, in contrast, would built a model for the normative takeover.
\\ It is no surprise that comparing experimental data to the predicted mean results in a low $R^2$ - $R^2$ is a measure for mean and variance, and there is no variance in our mean.%%%%schrott!
 Comparison with the $R^2$ of the statistical analysis is hard, because the regression analysis trains and reports the $R^2$ on the same data, while the Driver Model is completely based on theoretical background and then compared to experimental data. For example,...


\section{Outlook}
While we want to keep our model purely theoretical, it of course is possible to fit it to the experimental and literature data. This could not only improve the fit to the takeover time data, but also the fit to the substeps of the takeover (Hands on wheel etc.). 




\begin{table}
 \centering
  \begin{tabular}{ c | c | c | c | c | c }
    \hline
    
     & Data & Model \\ \hline
     Befelein - Baseline & 2.4 & 3.55 \\ \hline
     Befelein - calculate &3.8 & 3.7\\ \hline
     Befelein - search & 3.5 & 5.72\\ \hline
     Befelein - watch Video&4&5.7\\ \hline
     Befelein - Tetris& 4.7&5.7 \\ \hline
     Gold - Baseline &2.49&2.77\\ \hline
     Gold - Traffic&3.46 & 4.36\\ \hline
     Gold - Mental Workload & 2.69 & 2.92  \\ \hline
     Gold - Mental Workload and Traffic & 3.61 & 4.51\\ \hline
    
  \end{tabular}
 \caption{Comparison with Literature}
\end{table}\label{comlit}






















